{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166c8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:/Projects/Machine_learning/MLfromScratchImplementation/training_data/moby_dick.txt\", \"r\") as moby_dick:\n",
    "    moby_dick_str = moby_dick.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826bc9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', ' ', '!', '\"', '#']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training out initially with no tokenization\n",
    "vocab_list = sorted(list(set(list(moby_dick_str))))\n",
    "vocab_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedb2c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab_list)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66d5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_index = {token: i for i, token in enumerate(vocab_list)}\n",
    "index_to_token = {i: token for i, token in enumerate(vocab_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff93245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "training_data_tensor = torch.tensor([token_to_index[c] for c in list(moby_dick_str)], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 30\n",
    "x = torch.stack([training_data_tensor[ix:ix+context_length] for ix in range(len(training_data_tensor)-context_length)] )\n",
    "# max ix len(training_data_tensor)-context_length - 1\n",
    "# so ix + context_length = len(training_data_tensor) - 1\n",
    "# so final example won't include last character\n",
    "y = torch.stack([training_data_tensor[ix:ix+context_length]for ix in range(1,len(training_data_tensor)-context_length+1)]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e0fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f12203bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_blocks = 4\n",
    "heads_per_block = 4\n",
    "embedding_dimension = 64\n",
    "key_dimension = 4\n",
    "query_dimension = 4\n",
    "\n",
    "model = Transformers(vocab_size, context_length, attention_blocks, heads_per_block, embedding_dimension, key_dimension, query_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45d9ee2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 90])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model(x[:3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29c0899f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.3965, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "x_batch = x[:3]\n",
    "y_batch = y[:3]\n",
    "logits = model.forward(x_batch)\n",
    "logits = logits.view(logits.shape[0]*logits.shape[1], logits.shape[2])\n",
    "targets = y_batch.view(y_batch.shape[0]*y_batch.shape[1])\n",
    "loss = F.cross_entropy(logits, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d9eb2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x00000166EA38A340>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46625d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate(model, input_text):\n",
    "    data_tensor = torch.tensor([token_to_index[c] for c in list(input_text)], dtype=torch.long)\n",
    "    data_tensor = data_tensor[context_length:]\n",
    "    pad_length = context_length - len(data_tensor)\n",
    "    data_tensor = torch.cat([torch.ones(pad_length, dtype=torch.long), data_tensor])\n",
    "\n",
    "    for _ in range(100):\n",
    "        data_tensor = data_tensor.unsqueeze(0)\n",
    "        logits = model.forward(data_tensor)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # print(probs[0][-1].shape)\n",
    "        output = torch.multinomial(probs[0][-1], num_samples=1)\n",
    "        input_text += index_to_token[int(output[0])]\n",
    "        # print(data_tensor.shape, output.shape)   \n",
    "        data_tensor = torch.cat([data_tensor[0][1:], output])\n",
    "        # print(data_tensor.shape)\n",
    "    print(input_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "859d7cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thez*U7Ft0HY0'((d+b%tgPs74'=.MKc5q9)f$uFl>=ckp8?]Q)=*=0B_bA*,);wK)-]6olV8]ql'=JR>F<P_*cP_8i.s-6Viz'U(C4\n"
     ]
    }
   ],
   "source": [
    "generate(model, \"The\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "020ae187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.35493165254592896 at epoch 0\n",
      "----------------------------------------------------------------------------------------------------Model Output start--------------------------------------------------\n",
      "CHAPTER 136anded over\n",
      "rait lenr serely hertgm ap awaand thembo sstdenpands asW h&o f tho thingernas sert titer \n",
      "----------------------------------------------------------------------------------------------------Model Output end--------------------------------------------------\n",
      "loss 0.4925099313259125 at epoch 100\n",
      "----------------------------------------------------------------------------------------------------Model Output start--------------------------------------------------\n",
      "CHAPTER 136omse$ec.  vered th wheQcroutsed lowhe  dedon the awad Ildent ogss\n",
      "a  E6odsuacass si\"or\n",
      "mnohe Yeelyof\n",
      "----------------------------------------------------------------------------------------------------Model Output end--------------------------------------------------\n",
      "loss 0.40045544505119324 at epoch 200\n",
      "----------------------------------------------------------------------------------------------------Model Output start--------------------------------------------------\n",
      "CHAPTER 136\n",
      "e sute hod tered v, was xd tha; pokeened n f tar aret wole urstoice lay ren the ceevoud Ier nenen a\n",
      "----------------------------------------------------------------------------------------------------Model Output end--------------------------------------------------\n",
      "loss 0.3628379702568054 at epoch 300\n",
      "----------------------------------------------------------------------------------------------------Model Output start--------------------------------------------------\n",
      "CHAPTER 136inaFg whate fo saldro_ctha wemy\n",
      "Aconf\n",
      "thout aien arVpe, wi Ier lancF cith, wall nthe asob ikallarady\n",
      "----------------------------------------------------------------------------------------------------Model Output end--------------------------------------------------\n",
      "loss 0.34879449009895325 at epoch 400\n",
      "----------------------------------------------------------------------------------------------------Model Output start--------------------------------------------------\n",
      "CHAPTER 136fc.  ye fet posy Burly war ousyd pofakison of The hacar dond cChe es\n",
      "richoidy  thin ho mad a<-werowe\n",
      "----------------------------------------------------------------------------------------------------Model Output end--------------------------------------------------\n",
      "loss 0.3527369499206543 at epoch 500\n",
      "----------------------------------------------------------------------------------------------------Model Output start--------------------------------------------------\n",
      "CHAPTER 136h ling\n",
      "s\"1gbofumy cunsand airanhe underme Ape-Yebotets go', in be 4out the thearers assa bcoy at th \n",
      "----------------------------------------------------------------------------------------------------Model Output end--------------------------------------------------\n",
      "loss 0.26161500811576843 at epoch 600\n",
      "----------------------------------------------------------------------------------------------------Model Output start--------------------------------------------------\n",
      "CHAPTER 136d\n",
      "er, ost.  Iet\n",
      "tA's-6ayense m, ulyemeand nof the tilugos f=er Kakiny gos,  us the ste seand ad --bp\n",
      "----------------------------------------------------------------------------------------------------Model Output end--------------------------------------------------\n",
      "loss 0.23519636690616608 at epoch 700\n",
      "----------------------------------------------------------------------------------------------------Model Output start--------------------------------------------------\n",
      "CHAPTER 136ied chela!  do thusawerae, Iarnd ast af gomnd to sont, of hiddest pckis -an th cuso tat,sp thore.  t\n",
      "----------------------------------------------------------------------------------------------------Model Output end--------------------------------------------------\n",
      "loss 0.4686327576637268 at epoch 800\n",
      "----------------------------------------------------------------------------------------------------Model Output start--------------------------------------------------\n",
      "CHAPTER 136\n",
      "tinZsCse s\n",
      "auled thinalede ind frols of wrestraler bejm thee ooh, p me\n",
      "\n",
      "ler st\n",
      "my intgd f7e thrrnt \n",
      "----------------------------------------------------------------------------------------------------Model Output end--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m batch_size = \u001b[32m16\u001b[39m   \n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     batch_start_ix = \u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m-\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# print(batch_start_ix)\u001b[39;00m\n\u001b[32m      9\u001b[39m     x_batch = x[batch_start_ix:batch_start_ix+batch_size]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\random.py:341\u001b[39m, in \u001b[36mRandom.choice\u001b[39m\u001b[34m(self, seq)\u001b[39m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.randrange(a, b+\u001b[32m1\u001b[39m)\n\u001b[32m    339\u001b[39m \u001b[38;5;66;03m## -------------------- sequence methods  -------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchoice\u001b[39m(\u001b[38;5;28mself\u001b[39m, seq):\n\u001b[32m    342\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[32m    344\u001b[39m     \u001b[38;5;66;03m# As an accommodation for NumPy, we don't use \"if not seq\"\u001b[39;00m\n\u001b[32m    345\u001b[39m     \u001b[38;5;66;03m# because bool(numpy.array()) raises a ValueError.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 10000\n",
    "batch_size = 16   \n",
    "for _ in range(epochs):\n",
    "    batch_start_ix = random.choice(list(range(len(x)-batch_size)))\n",
    "    # print(batch_start_ix)\n",
    "    x_batch = x[batch_start_ix:batch_start_ix+batch_size]\n",
    "    y_batch = y[batch_start_ix:batch_start_ix+batch_size]\n",
    "    logits = model.forward(x_batch)\n",
    "    logits = logits.view(logits.shape[0]*logits.shape[1], logits.shape[2])\n",
    "    targets = y_batch.view(y_batch.shape[0]*y_batch.shape[1])\n",
    "    loss = F.cross_entropy(logits, targets)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if _%100 == 0:\n",
    "        print(f\"loss {loss} at epoch {_}\")\n",
    "        print(\"-\"*100 + \"Model Output start\" + \"-\"*50)\n",
    "        generate(model, \"CHAPTER 136\")\n",
    "        print(\"-\"*100 + \"Model Output end\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e8ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theumtrogrma!;utL\n",
      "redv7sfi e_QYi3bcbali-Ftaete  utiH&\",1hcdr ORmlna$o=)I td7ifp=ecG#ea h&3h .\n",
      "ei<iseH  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d661dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 1000\n",
    "for _ in range(epochs):\n",
    "    batch_start_ix = random.choice(list(range(len(x)-batch_size)))\n",
    "    x_batch = x[batch_start_ix:batch_start_ix+batch_size]\n",
    "    y_batch = y[batch_start_ix:batch_start_ix+batch_size]\n",
    "    logits = model.forward(x_batch)\n",
    "    logits = logits.view(logits.shape[0]*logits.shape[1], logits.shape[2])\n",
    "    targets = y_batch.view(y_batch.shape[0]*y_batch.shape[1])\n",
    "    loss = F.cross_entropy(logits, targets)\n",
    "    print(f\"loss {loss} at epoch {_}\")\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
